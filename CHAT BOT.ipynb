{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on Paper End to End Memory Networks - Jason Weston,Sainbayar Sukhbaatar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training data\n",
    "with open('train_qa.txt','rb') as f:\n",
    "    train_qa = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the testing data\n",
    "with open('test_qa.txt','rb') as f:\n",
    "    test_qa = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Let's check the type of data\n",
    "print(type(train_qa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the training data is 10000\n"
     ]
    }
   ],
   "source": [
    "# Let's check the length of the training data\n",
    "print(f\"The length of the training data is {len(train_qa)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the test data is 1000\n"
     ]
    }
   ],
   "source": [
    "# Let's check the length of the test data\n",
    "print(f\"The length of the test data is {len(test_qa)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Sandra',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'office',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'office', '?'],\n",
       " 'yes')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check any training data.\n",
    "train_qa[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement: Sandra went back to the hallway . Sandra moved to the office .\n",
      "\n",
      "\n",
      "Question: Is Sandra in the office ?\n",
      "\n",
      "\n",
      "Answer: yes\n"
     ]
    }
   ],
   "source": [
    "# Let's organise it in the proper format\n",
    "statement = ' '.join(train_qa[10][0])\n",
    "question = ' '.join(train_qa[10][1])\n",
    "answer = train_qa[10][2]\n",
    "\n",
    "print(f\"Statement: {statement}\")\n",
    "print('\\n')\n",
    "print(f\"Question: {question}\")\n",
    "print('\\n')\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our model will take Statement and Question as input and try to predict the Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a vocabulary which will consist of all the words present in training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since training data and testing data are list.We can add them up to create a new list which consist of both \n",
    "# train and test data\n",
    "data = train_qa+test_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary should only consist of unique words. So lets create a vocab variable which will only consist of unique words\n",
    "# from both train and test data\n",
    "\n",
    "vocabulary = set() # empty set. It will autmatically remove the duplicate words\n",
    "\n",
    "for statement,question,answer in data:\n",
    "    vocabulary = vocabulary.union(set(statement))\n",
    "    vocabulary = vocabulary.union(set(question))\n",
    "\n",
    "# Let's add the yes and no to the vocabulary\n",
    "vocabulary.add('no')\n",
    "vocabulary.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'journeyed', 'grabbed', 'in', 'went', 'bedroom', 'moved', 'took', 'John', 'Mary', 'kitchen', 'hallway', 'garden', 'put', 'got', 'picked', '.', 'dropped', 'up', 'travelled', 'discarded', 'yes', 'no', 'football', '?', 'to', 'the', 'Sandra', 'bathroom', 'office', 'left', 'Is', 'Daniel', 'back', 'there', 'milk', 'apple', 'down'}\n"
     ]
    }
   ],
   "source": [
    "# Let's check the set of all the possible words in vocabulary\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in vocabulary is 38\n"
     ]
    }
   ],
   "source": [
    "# Let's take the length of vocabulary\n",
    "# We add 1 so that we can later use it in pad_sequences and index 0 is a place holder.\n",
    "vocabulary_length = len(vocabulary)+1\n",
    "\n",
    "print(f\"Total number of words in vocabulary is {vocabulary_length}\") # 37 unique words a nd 1 place holder for pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of longest statement is 156\n"
     ]
    }
   ],
   "source": [
    "# Now, we have to put the statements and questions in a right format so that it can be understood and trained by our RNN model\n",
    "# We will use Tokenizer and pad_sequences to convert them into right format\n",
    "\n",
    "\n",
    "# Let's check the maximum length of statement present in the data\n",
    "\n",
    "# List of length of all the statements\n",
    "all_statement_length = [len(item[0]) for item in data]\n",
    "\n",
    "# Maximum value present in the all_statement_legnth will the length of the longest statement\n",
    "max_statement_length = max(all_statement_length)\n",
    "\n",
    "# Longest statement\n",
    "print(f\"The length of longest statement is {max_statement_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of longest question is 6\n"
     ]
    }
   ],
   "source": [
    "# Let's check the maximum length of question present in the data\n",
    "\n",
    "# List of length of all the questions\n",
    "all_questions_length = [len(item[1]) for item in data]\n",
    "\n",
    "# Maximum value present in the all_questions_legnth will the length of the longest question\n",
    "max_question_length = max(all_questions_length)\n",
    "\n",
    "# Longest statement\n",
    "print(f\"The length of longest question is {max_question_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toeknization and pad sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer is used to vectorize the data.Unique number is assigned to each word present in the vocabulary\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journeyed': 1,\n",
       " 'grabbed': 2,\n",
       " 'in': 3,\n",
       " 'went': 4,\n",
       " 'bedroom': 5,\n",
       " 'moved': 6,\n",
       " 'took': 7,\n",
       " 'john': 8,\n",
       " 'mary': 9,\n",
       " 'kitchen': 10,\n",
       " 'hallway': 11,\n",
       " 'garden': 12,\n",
       " 'put': 13,\n",
       " 'got': 14,\n",
       " 'picked': 15,\n",
       " '.': 16,\n",
       " 'dropped': 17,\n",
       " 'up': 18,\n",
       " 'travelled': 19,\n",
       " 'discarded': 20,\n",
       " 'yes': 21,\n",
       " 'no': 22,\n",
       " 'football': 23,\n",
       " '?': 24,\n",
       " 'to': 25,\n",
       " 'the': 26,\n",
       " 'sandra': 27,\n",
       " 'bathroom': 28,\n",
       " 'office': 29,\n",
       " 'left': 30,\n",
       " 'is': 31,\n",
       " 'daniel': 32,\n",
       " 'back': 33,\n",
       " 'there': 34,\n",
       " 'milk': 35,\n",
       " 'apple': 36,\n",
       " 'down': 37}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the tokenizer object. It will be a dictionary with every word assigned a unique number\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's convert the statements,question,and answers into correct format.\n",
    "# First by seperating statement,question,answer from training data and testing data.\n",
    "# Then assigning each word there matching word index.\n",
    "# and making each statement of same length and each question of same lenght using pad sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function that will vectorize each statements,questions ans answer using pad sequences\n",
    "def vectorize(data,word_index = tokenizer.word_index,max_statement_length = max_statement_length,max_question_length = max_question_length):\n",
    "    \n",
    "    # statements\n",
    "    statements = []\n",
    "    # questions\n",
    "    questions = []\n",
    "    # answers\n",
    "    answers = []\n",
    "    \n",
    "    for statement,question,answer in data:\n",
    "        \n",
    "        # for each statement\n",
    "        s = [word_index[word.lower()] for word in statement]\n",
    "        \n",
    "        # for each question\n",
    "        q = [word_index[word.lower()] for word in question]\n",
    "        \n",
    "        y = np.zeros(len(word_index)+1)\n",
    "        \n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        statements.append(s)\n",
    "        questions.append(q)\n",
    "        answers.append(y)\n",
    "    \n",
    "    # doing the pad_sequences and returning\n",
    "    return (pad_sequences(statements,maxlen = max_statement_length),pad_sequences(questions,maxlen=max_question_length),np.array(answers))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply the above function on training data\n",
    "train_statements,train_questions,train_answers = vectorize(train_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's appy the above function on testing data\n",
    "test_statements,test_questions,test_answers = vectorize(test_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 26,  5, 16],\n",
       "       [ 0,  0,  0, ..., 26, 11, 16],\n",
       "       [ 0,  0,  0, ..., 26, 28, 16],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 26,  5, 16],\n",
       "       [ 0,  0,  0, ..., 35, 34, 16],\n",
       "       [ 0,  0,  0, ..., 36, 34, 16]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the train_statements\n",
    "train_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31, 27,  3, 26, 11, 24],\n",
       "       [31, 32,  3, 26, 28, 24],\n",
       "       [31, 32,  3, 26, 29, 24],\n",
       "       ...,\n",
       "       [31, 27,  3, 26, 11, 24],\n",
       "       [31,  9,  3, 26, 10, 24],\n",
       "       [31,  9,  3, 26,  5, 24]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the train_questions\n",
    "train_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0., 5012., 4988.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the train_answers\n",
    "# please note that each item is of length of vocabulary and the value of yes will be 1 at index coresponding to its toekinzer.word_index value\n",
    "# same is for no. If answer is yes 1 will be at index 21 and if no 1 will be at index 22.Rest will be 0\n",
    "\n",
    "# we can check this is summing the value of all the items in train answer\n",
    "sum(train_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index at 21 and 22 only have value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create our model\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input,Activation,Dense,Permute,Dropout,add,dot,concatenate,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have two inputs - statements and questions.We will create a place holder for both statements and questions\n",
    "# place holder shape = (max_statement_length,batch_size)\n",
    "statement_sequence = Input(shape =(max_statement_length,))\n",
    "question_sequence = Input(shape = (max_question_length,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input encoder M\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocabulary_length,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.4))\n",
    "\n",
    "# OUTPUT will be the form \n",
    "# (samples,max_statement_lenght,embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input encoder C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocabulary_length,output_dim=max_question_length))\n",
    "input_encoder_c.add(Dropout(0.4))\n",
    "\n",
    "# OUTPUT\n",
    "# (samples,max_statement_length,max_question_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question encoder \n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim = vocabulary_length,output_dim=64,input_length = max_question_length))\n",
    "question_encoder.add(Dropout(0.4))\n",
    "\n",
    "# OUTPUT\n",
    "# (samples,max_question_len,embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets encode the statement sequence and question sequence by passing them to input_encoder_m,input_encoder_c and question_encoder\n",
    "input_encoded_m = input_encoder_m(statement_sequence)\n",
    "\n",
    "input_encoded_c = input_encoder_c(statement_sequence)\n",
    "\n",
    "question_encoded = question_encoder(question_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we take the dot product of input_encoded_m,question encoded\n",
    "dot_product = dot([input_encoded_m,question_encoded],axes=(2,2))\n",
    "\n",
    "# Let's apply the sofmax axtivation function on dot_product\n",
    "dot_product = Activation('softmax')(dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now adding the dot_product to input_encoded_c\n",
    "output_memory = add([dot_product,input_encoded_c])\n",
    "\n",
    "# To get the required dimension of the input\n",
    "output_memory = Permute((2,1))(output_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_memory and question encoded are added and then passed through weights and softmax activation to predict final ouput \n",
    "prediction=concatenate([output_memory,question_encoded])\n",
    "\n",
    "prediction = LSTM(32)(prediction)\n",
    "\n",
    "prediction = Dropout(0.5)(prediction)\n",
    "\n",
    "prediction = Dense(vocabulary_length)(prediction) # output layer\n",
    "\n",
    "prediction = Activation('softmax')(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, 64)     2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[0][0]               \n",
      "                                                                 sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 6, 156)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_3[0][0]                  \n",
      "                                                                 sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Now everything is ready.Let's arrange them to create our model.\n",
    "model = Model([statement_sequence,question_sequence],prediction)\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "313/313 [==============================] - 23s 31ms/step - loss: 0.9018 - accuracy: 0.5063 - val_loss: 0.7022 - val_accuracy: 0.4970\n",
      "Epoch 2/150\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.7053 - accuracy: 0.5024 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 3/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.6960 - accuracy: 0.4975 - val_loss: 0.6952 - val_accuracy: 0.4970\n",
      "Epoch 4/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6956 - accuracy: 0.4986 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 5/150\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6937 - accuracy: 0.5119 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
      "Epoch 6/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6951 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 7/150\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6938 - accuracy: 0.5078 - val_loss: 0.6941 - val_accuracy: 0.4970\n",
      "Epoch 8/150\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.6937 - accuracy: 0.5056 - val_loss: 0.6963 - val_accuracy: 0.5030\n",
      "Epoch 9/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.6944 - accuracy: 0.5051 - val_loss: 0.6943 - val_accuracy: 0.4830\n",
      "Epoch 10/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.6945 - accuracy: 0.4986 - val_loss: 0.6951 - val_accuracy: 0.4970\n",
      "Epoch 11/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.6941 - accuracy: 0.5040 - val_loss: 0.6982 - val_accuracy: 0.4970\n",
      "Epoch 12/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.6937 - accuracy: 0.5076 - val_loss: 0.6948 - val_accuracy: 0.4960\n",
      "Epoch 13/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.6928 - accuracy: 0.5184 - val_loss: 0.6947 - val_accuracy: 0.5080\n",
      "Epoch 14/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.6904 - accuracy: 0.5284 - val_loss: 0.6944 - val_accuracy: 0.5230\n",
      "Epoch 15/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.6653 - accuracy: 0.5951 - val_loss: 0.6415 - val_accuracy: 0.6280\n",
      "Epoch 16/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.6347 - accuracy: 0.6439 - val_loss: 0.6299 - val_accuracy: 0.6440\n",
      "Epoch 17/150\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.6202 - accuracy: 0.6568 - val_loss: 0.6157 - val_accuracy: 0.6660\n",
      "Epoch 18/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.6115 - accuracy: 0.6749 - val_loss: 0.6066 - val_accuracy: 0.6690\n",
      "Epoch 19/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.5958 - accuracy: 0.6887 - val_loss: 0.5991 - val_accuracy: 0.6810\n",
      "Epoch 20/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.5895 - accuracy: 0.6924 - val_loss: 0.5841 - val_accuracy: 0.6950\n",
      "Epoch 21/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.5761 - accuracy: 0.7088 - val_loss: 0.6076 - val_accuracy: 0.6810\n",
      "Epoch 22/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.5686 - accuracy: 0.7173 - val_loss: 0.5787 - val_accuracy: 0.6980\n",
      "Epoch 23/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.5530 - accuracy: 0.7201 - val_loss: 0.5588 - val_accuracy: 0.7210\n",
      "Epoch 24/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.5493 - accuracy: 0.7317 - val_loss: 0.5524 - val_accuracy: 0.7280\n",
      "Epoch 25/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.5352 - accuracy: 0.7434 - val_loss: 0.5700 - val_accuracy: 0.7160\n",
      "Epoch 26/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.5302 - accuracy: 0.7397 - val_loss: 0.5369 - val_accuracy: 0.7390\n",
      "Epoch 27/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.5196 - accuracy: 0.7492 - val_loss: 0.5302 - val_accuracy: 0.7430\n",
      "Epoch 28/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.5109 - accuracy: 0.7558 - val_loss: 0.5124 - val_accuracy: 0.7460\n",
      "Epoch 29/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.4997 - accuracy: 0.7592 - val_loss: 0.4984 - val_accuracy: 0.7560\n",
      "Epoch 30/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.4955 - accuracy: 0.7628 - val_loss: 0.4982 - val_accuracy: 0.7490\n",
      "Epoch 31/150\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.4950 - accuracy: 0.7633 - val_loss: 0.4868 - val_accuracy: 0.7560\n",
      "Epoch 32/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.4842 - accuracy: 0.7640 - val_loss: 0.5117 - val_accuracy: 0.7440\n",
      "Epoch 33/150\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.4855 - accuracy: 0.7721 - val_loss: 0.4877 - val_accuracy: 0.7580\n",
      "Epoch 34/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.4800 - accuracy: 0.7721 - val_loss: 0.4810 - val_accuracy: 0.7580\n",
      "Epoch 35/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.4750 - accuracy: 0.7763 - val_loss: 0.4631 - val_accuracy: 0.7600\n",
      "Epoch 36/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4766 - accuracy: 0.7739 - val_loss: 0.4721 - val_accuracy: 0.7620\n",
      "Epoch 37/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.4612 - accuracy: 0.7820 - val_loss: 0.4582 - val_accuracy: 0.7650\n",
      "Epoch 38/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4620 - accuracy: 0.7863 - val_loss: 0.4644 - val_accuracy: 0.7630\n",
      "Epoch 39/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4567 - accuracy: 0.7852 - val_loss: 0.4512 - val_accuracy: 0.7640\n",
      "Epoch 40/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4476 - accuracy: 0.7919 - val_loss: 0.4579 - val_accuracy: 0.7780\n",
      "Epoch 41/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4427 - accuracy: 0.7934 - val_loss: 0.4339 - val_accuracy: 0.7890\n",
      "Epoch 42/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.4363 - accuracy: 0.8023 - val_loss: 0.4336 - val_accuracy: 0.7900\n",
      "Epoch 43/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4363 - accuracy: 0.7974 - val_loss: 0.4217 - val_accuracy: 0.8020\n",
      "Epoch 44/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.4253 - accuracy: 0.8081 - val_loss: 0.4322 - val_accuracy: 0.7910\n",
      "Epoch 45/150\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.81 - 7s 23ms/step - loss: 0.4162 - accuracy: 0.8101 - val_loss: 0.4227 - val_accuracy: 0.8000\n",
      "Epoch 46/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.4116 - accuracy: 0.8153 - val_loss: 0.4170 - val_accuracy: 0.8010\n",
      "Epoch 47/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4097 - accuracy: 0.8183 - val_loss: 0.4243 - val_accuracy: 0.7960\n",
      "Epoch 48/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.4024 - accuracy: 0.8194 - val_loss: 0.4189 - val_accuracy: 0.7940\n",
      "Epoch 49/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4063 - accuracy: 0.8160 - val_loss: 0.4175 - val_accuracy: 0.8060\n",
      "Epoch 50/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.3970 - accuracy: 0.8244 - val_loss: 0.4172 - val_accuracy: 0.8160A: 0s - loss: 0.3976 - ac\n",
      "Epoch 51/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3914 - accuracy: 0.8272 - val_loss: 0.4124 - val_accuracy: 0.8130\n",
      "Epoch 52/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3932 - accuracy: 0.8239 - val_loss: 0.4109 - val_accuracy: 0.8100\n",
      "Epoch 53/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.3857 - accuracy: 0.8260 - val_loss: 0.4085 - val_accuracy: 0.8110\n",
      "Epoch 54/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3754 - accuracy: 0.8325 - val_loss: 0.4037 - val_accuracy: 0.8110\n",
      "Epoch 55/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3758 - accuracy: 0.8366 - val_loss: 0.4140 - val_accuracy: 0.8140\n",
      "Epoch 56/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3734 - accuracy: 0.8334 - val_loss: 0.3901 - val_accuracy: 0.8130\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3705 - accuracy: 0.8341 - val_loss: 0.3943 - val_accuracy: 0.8230\n",
      "Epoch 58/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.3690 - accuracy: 0.8372 - val_loss: 0.4237 - val_accuracy: 0.8040\n",
      "Epoch 59/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.3698 - accuracy: 0.8384 - val_loss: 0.3932 - val_accuracy: 0.8210\n",
      "Epoch 60/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.3637 - accuracy: 0.8419 - val_loss: 0.3989 - val_accuracy: 0.8240\n",
      "Epoch 61/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3646 - accuracy: 0.8452 - val_loss: 0.4075 - val_accuracy: 0.8120\n",
      "Epoch 62/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3550 - accuracy: 0.8433 - val_loss: 0.4389 - val_accuracy: 0.8220\n",
      "Epoch 63/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3619 - accuracy: 0.8404 - val_loss: 0.3940 - val_accuracy: 0.8180\n",
      "Epoch 64/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3579 - accuracy: 0.8438 - val_loss: 0.3921 - val_accuracy: 0.8230\n",
      "Epoch 65/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.3563 - accuracy: 0.8449 - val_loss: 0.4104 - val_accuracy: 0.8150\n",
      "Epoch 66/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.3410 - accuracy: 0.8521 - val_loss: 0.3915 - val_accuracy: 0.8260\n",
      "Epoch 67/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3541 - accuracy: 0.8489 - val_loss: 0.3945 - val_accuracy: 0.8240\n",
      "Epoch 68/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.3472 - accuracy: 0.8486 - val_loss: 0.3968 - val_accuracy: 0.8190\n",
      "Epoch 69/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3471 - accuracy: 0.8532 - val_loss: 0.4083 - val_accuracy: 0.8060\n",
      "Epoch 70/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.3456 - accuracy: 0.8506 - val_loss: 0.4162 - val_accuracy: 0.8140\n",
      "Epoch 71/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3484 - accuracy: 0.8458 - val_loss: 0.4118 - val_accuracy: 0.8340\n",
      "Epoch 72/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3417 - accuracy: 0.8534 - val_loss: 0.3911 - val_accuracy: 0.8220\n",
      "Epoch 73/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3432 - accuracy: 0.8528 - val_loss: 0.3985 - val_accuracy: 0.8260\n",
      "Epoch 74/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3414 - accuracy: 0.8536 - val_loss: 0.4045 - val_accuracy: 0.8210\n",
      "Epoch 75/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3386 - accuracy: 0.8521 - val_loss: 0.3978 - val_accuracy: 0.8180\n",
      "Epoch 76/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3304 - accuracy: 0.8580 - val_loss: 0.4027 - val_accuracy: 0.8190\n",
      "Epoch 77/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3374 - accuracy: 0.8556 - val_loss: 0.4026 - val_accuracy: 0.8240\n",
      "Epoch 78/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3360 - accuracy: 0.8580 - val_loss: 0.3983 - val_accuracy: 0.8230\n",
      "Epoch 79/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3268 - accuracy: 0.8591 - val_loss: 0.4045 - val_accuracy: 0.8260\n",
      "Epoch 80/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.3343 - accuracy: 0.8573 - val_loss: 0.3981 - val_accuracy: 0.8220\n",
      "Epoch 81/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3297 - accuracy: 0.8570 - val_loss: 0.4018 - val_accuracy: 0.8240\n",
      "Epoch 82/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3265 - accuracy: 0.8624 - val_loss: 0.4290 - val_accuracy: 0.8130\n",
      "Epoch 83/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3277 - accuracy: 0.8599 - val_loss: 0.4116 - val_accuracy: 0.8270\n",
      "Epoch 84/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.3250 - accuracy: 0.8599 - val_loss: 0.4041 - val_accuracy: 0.8190\n",
      "Epoch 85/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3231 - accuracy: 0.8606 - val_loss: 0.4080 - val_accuracy: 0.8280\n",
      "Epoch 86/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3205 - accuracy: 0.8609 - val_loss: 0.4066 - val_accuracy: 0.8190\n",
      "Epoch 87/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3240 - accuracy: 0.8608 - val_loss: 0.4060 - val_accuracy: 0.8220\n",
      "Epoch 88/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3196 - accuracy: 0.8618 - val_loss: 0.4030 - val_accuracy: 0.8180\n",
      "Epoch 89/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3254 - accuracy: 0.8580 - val_loss: 0.4183 - val_accuracy: 0.8180\n",
      "Epoch 90/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3145 - accuracy: 0.8650 - val_loss: 0.4001 - val_accuracy: 0.8250\n",
      "Epoch 91/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3225 - accuracy: 0.8634 - val_loss: 0.4163 - val_accuracy: 0.8210\n",
      "Epoch 92/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3169 - accuracy: 0.8660 - val_loss: 0.4135 - val_accuracy: 0.8330\n",
      "Epoch 93/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3057 - accuracy: 0.8707 - val_loss: 0.4291 - val_accuracy: 0.8230\n",
      "Epoch 94/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3113 - accuracy: 0.8687 - val_loss: 0.4089 - val_accuracy: 0.8310\n",
      "Epoch 95/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3114 - accuracy: 0.8641 - val_loss: 0.4056 - val_accuracy: 0.8210\n",
      "Epoch 96/150\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.3119 - accuracy: 0.8676 - val_loss: 0.4052 - val_accuracy: 0.8260\n",
      "Epoch 97/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3026 - accuracy: 0.8724 - val_loss: 0.4352 - val_accuracy: 0.8190\n",
      "Epoch 98/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3104 - accuracy: 0.8633 - val_loss: 0.4303 - val_accuracy: 0.8180\n",
      "Epoch 99/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3076 - accuracy: 0.8690 - val_loss: 0.4194 - val_accuracy: 0.8180\n",
      "Epoch 100/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3015 - accuracy: 0.8698 - val_loss: 0.4274 - val_accuracy: 0.8220\n",
      "Epoch 101/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3009 - accuracy: 0.8732 - val_loss: 0.4214 - val_accuracy: 0.8210\n",
      "Epoch 102/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3077 - accuracy: 0.8713 - val_loss: 0.4144 - val_accuracy: 0.8210\n",
      "Epoch 103/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2996 - accuracy: 0.8756 - val_loss: 0.4127 - val_accuracy: 0.8240\n",
      "Epoch 104/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3001 - accuracy: 0.8728 - val_loss: 0.4120 - val_accuracy: 0.8190\n",
      "Epoch 105/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3051 - accuracy: 0.8730 - val_loss: 0.4127 - val_accuracy: 0.8230\n",
      "Epoch 106/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.3059 - accuracy: 0.8740 - val_loss: 0.4207 - val_accuracy: 0.8230\n",
      "Epoch 107/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.2965 - accuracy: 0.8742 - val_loss: 0.4326 - val_accuracy: 0.8190\n",
      "Epoch 108/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2941 - accuracy: 0.8770 - val_loss: 0.4289 - val_accuracy: 0.8150\n",
      "Epoch 109/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.2966 - accuracy: 0.8760 - val_loss: 0.4202 - val_accuracy: 0.8180\n",
      "Epoch 110/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3009 - accuracy: 0.8763 - val_loss: 0.4257 - val_accuracy: 0.8130\n",
      "Epoch 111/150\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.2931 - accuracy: 0.8795 - val_loss: 0.4326 - val_accuracy: 0.8200\n",
      "Epoch 112/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2957 - accuracy: 0.8802 - val_loss: 0.4149 - val_accuracy: 0.8210\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 24ms/step - loss: 0.2983 - accuracy: 0.8748 - val_loss: 0.4108 - val_accuracy: 0.8260\n",
      "Epoch 114/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2916 - accuracy: 0.8776 - val_loss: 0.4199 - val_accuracy: 0.8220\n",
      "Epoch 115/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2942 - accuracy: 0.8760 - val_loss: 0.4251 - val_accuracy: 0.8260\n",
      "Epoch 116/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2834 - accuracy: 0.8808 - val_loss: 0.4447 - val_accuracy: 0.8200\n",
      "Epoch 117/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2875 - accuracy: 0.8798 - val_loss: 0.4222 - val_accuracy: 0.8210\n",
      "Epoch 118/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2879 - accuracy: 0.8784 - val_loss: 0.4270 - val_accuracy: 0.8130\n",
      "Epoch 119/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2828 - accuracy: 0.8815 - val_loss: 0.4147 - val_accuracy: 0.8230\n",
      "Epoch 120/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2884 - accuracy: 0.8774 - val_loss: 0.4378 - val_accuracy: 0.8250\n",
      "Epoch 121/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2836 - accuracy: 0.8814 - val_loss: 0.4373 - val_accuracy: 0.8250\n",
      "Epoch 122/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.2811 - accuracy: 0.8806 - val_loss: 0.4429 - val_accuracy: 0.8260\n",
      "Epoch 123/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2801 - accuracy: 0.8839 - val_loss: 0.4465 - val_accuracy: 0.8220\n",
      "Epoch 124/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.2834 - accuracy: 0.8828 - val_loss: 0.4413 - val_accuracy: 0.8190\n",
      "Epoch 125/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2807 - accuracy: 0.8821 - val_loss: 0.4485 - val_accuracy: 0.8230\n",
      "Epoch 126/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2806 - accuracy: 0.8854 - val_loss: 0.4423 - val_accuracy: 0.8190\n",
      "Epoch 127/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2802 - accuracy: 0.8807 - val_loss: 0.4362 - val_accuracy: 0.8150\n",
      "Epoch 128/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2768 - accuracy: 0.8891 - val_loss: 0.4504 - val_accuracy: 0.8140\n",
      "Epoch 129/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2794 - accuracy: 0.8817 - val_loss: 0.4393 - val_accuracy: 0.8230\n",
      "Epoch 130/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2770 - accuracy: 0.8864 - val_loss: 0.4701 - val_accuracy: 0.8140\n",
      "Epoch 131/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2720 - accuracy: 0.8891 - val_loss: 0.4601 - val_accuracy: 0.8220\n",
      "Epoch 132/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2723 - accuracy: 0.8851 - val_loss: 0.4520 - val_accuracy: 0.8180\n",
      "Epoch 133/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.2745 - accuracy: 0.8847 - val_loss: 0.4732 - val_accuracy: 0.8200\n",
      "Epoch 134/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2755 - accuracy: 0.8867 - val_loss: 0.4475 - val_accuracy: 0.8180\n",
      "Epoch 135/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.2746 - accuracy: 0.8877 - val_loss: 0.4286 - val_accuracy: 0.8180\n",
      "Epoch 136/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2722 - accuracy: 0.8868 - val_loss: 0.4569 - val_accuracy: 0.8170\n",
      "Epoch 137/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2668 - accuracy: 0.8899 - val_loss: 0.4314 - val_accuracy: 0.8210\n",
      "Epoch 138/150\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.2704 - accuracy: 0.8883 - val_loss: 0.4426 - val_accuracy: 0.8180\n",
      "Epoch 139/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.2690 - accuracy: 0.8887 - val_loss: 0.4489 - val_accuracy: 0.8210\n",
      "Epoch 140/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2711 - accuracy: 0.8871 - val_loss: 0.4651 - val_accuracy: 0.8180\n",
      "Epoch 141/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2686 - accuracy: 0.8912 - val_loss: 0.4530 - val_accuracy: 0.8080\n",
      "Epoch 142/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2703 - accuracy: 0.8885 - val_loss: 0.4338 - val_accuracy: 0.8210\n",
      "Epoch 143/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2706 - accuracy: 0.8896 - val_loss: 0.4699 - val_accuracy: 0.8180\n",
      "Epoch 144/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.2734 - accuracy: 0.8847 - val_loss: 0.4564 - val_accuracy: 0.8170\n",
      "Epoch 145/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2667 - accuracy: 0.8893 - val_loss: 0.4353 - val_accuracy: 0.8160\n",
      "Epoch 146/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2721 - accuracy: 0.8890 - val_loss: 0.4621 - val_accuracy: 0.8170\n",
      "Epoch 147/150\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2635 - accuracy: 0.8874 - val_loss: 0.4611 - val_accuracy: 0.8140\n",
      "Epoch 148/150\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.2627 - accuracy: 0.8908 - val_loss: 0.4831 - val_accuracy: 0.8170\n",
      "Epoch 149/150\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2612 - accuracy: 0.8914 - val_loss: 0.4641 - val_accuracy: 0.8120\n",
      "Epoch 150/150\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2666 - accuracy: 0.8904 - val_loss: 0.4688 - val_accuracy: 0.8110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ac553a1c0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's fit our model. We will use 32 as batch size,epochs=150\n",
    "model.fit([train_statements,train_questions],train_answers,batch_size=32,epochs = 150,validation_data = ([test_statements,test_questions],test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.901824</td>\n",
       "      <td>0.5063</td>\n",
       "      <td>0.702210</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.705324</td>\n",
       "      <td>0.5024</td>\n",
       "      <td>0.693224</td>\n",
       "      <td>0.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.696025</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.695179</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.693308</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.693650</td>\n",
       "      <td>0.5119</td>\n",
       "      <td>0.693446</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.901824    0.5063  0.702210         0.497\n",
       "1  0.705324    0.5024  0.693224         0.503\n",
       "2  0.696025    0.4975  0.695179         0.497\n",
       "3  0.695556    0.4986  0.693308         0.497\n",
       "4  0.693650    0.5119  0.693446         0.497"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EVALUATION\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "\n",
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict on testing data\n",
    "prediction = model.predict(([test_statements,test_questions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = prediction.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 21, 21, 21, 21, 22, 22, 21, 21, 21, 21, 21, 21, 22, 22, 21, 21,\n",
       "       22, 22, 21, 21, 22, 21, 22, 22, 21, 21, 22, 22, 21, 21, 22, 22, 21,\n",
       "       21, 22, 21, 21, 21, 22, 21, 22, 22, 22, 21, 21, 21, 22, 21, 21, 21,\n",
       "       22, 21, 21, 21, 22, 22, 21, 22, 21, 22, 22, 21, 21, 21, 21, 21, 21,\n",
       "       22, 21, 22, 21, 22, 21, 21, 21, 21, 21, 22, 22, 21, 22, 22, 21, 22,\n",
       "       22, 21, 22, 22, 21, 21, 22, 22, 22, 22, 21, 21, 21, 21, 22, 22, 22,\n",
       "       22, 22, 22, 22, 22, 22, 22, 22, 22, 21, 21, 21, 21, 22, 21, 21, 21,\n",
       "       21, 22, 21, 21, 21, 21, 22, 21, 21, 22, 21, 22, 21, 22, 21, 22, 22,\n",
       "       22, 22, 21, 22, 22, 21, 22, 22, 21, 21, 22, 21, 22, 22, 21, 21, 22,\n",
       "       21, 22, 22, 21, 22, 22, 21, 21, 21, 22, 21, 21, 22, 21, 22, 22, 21,\n",
       "       21, 22, 22, 22, 21, 21, 21, 22, 22, 22, 21, 21, 21, 21, 22, 21, 21,\n",
       "       21, 22, 22, 21, 21, 22, 22, 21, 21, 21, 22, 22, 22, 21, 21, 22, 21,\n",
       "       22, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 21, 22, 22, 22, 21,\n",
       "       21, 22, 21, 21, 21, 21, 22, 21, 22, 22, 21, 22, 22, 21, 21, 22, 21,\n",
       "       21, 21, 22, 22, 21, 22, 22, 21, 21, 21, 22, 21, 21, 21, 22, 21, 21,\n",
       "       21, 21, 21, 22, 21, 22, 21, 21, 22, 22, 21, 21, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 21, 21, 21, 22, 22, 21, 22, 21, 22, 21, 21, 21, 22, 22,\n",
       "       22, 21, 22, 21, 22, 22, 22, 21, 21, 22, 21, 21, 22, 21, 21, 22, 21,\n",
       "       21, 21, 22, 22, 21, 21, 21, 22, 21, 22, 21, 21, 21, 22, 21, 21, 21,\n",
       "       22, 22, 22, 22, 22, 22, 22, 21, 22, 21, 21, 21, 21, 21, 22, 21, 21,\n",
       "       22, 21, 22, 22, 21, 22, 22, 21, 21, 22, 21, 21, 21, 21, 21, 22, 21,\n",
       "       21, 21, 21, 21, 22, 22, 21, 22, 22, 22, 21, 22, 22, 22, 22, 21, 22,\n",
       "       22, 22, 21, 22, 21, 21, 21, 21, 21, 21, 22, 22, 21, 22, 21, 22, 22,\n",
       "       22, 22, 22, 21, 22, 21, 21, 21, 21, 21, 21, 21, 21, 22, 21, 21, 21,\n",
       "       22, 22, 21, 21, 22, 22, 21, 22, 21, 21, 22, 21, 21, 22, 21, 22, 21,\n",
       "       22, 21, 22, 21, 22, 22, 21, 21, 21, 21, 21, 22, 21, 21, 21, 21, 21,\n",
       "       21, 22, 21, 22, 22, 22, 22, 21, 21, 22, 21, 21, 22, 22, 21, 22, 21,\n",
       "       21, 22, 22, 21, 21, 21, 21, 21, 21, 22, 21, 21, 22, 21, 21, 21, 21,\n",
       "       21, 21, 21, 22, 21, 22, 21, 22, 21, 21, 21, 21, 22, 21, 21, 22, 21,\n",
       "       21, 21, 22, 21, 21, 21, 22, 22, 21, 21, 22, 22, 21, 22, 21, 21, 21,\n",
       "       22, 22, 22, 21, 22, 21, 22, 21, 21, 21, 22, 22, 22, 21, 21, 22, 21,\n",
       "       21, 21, 22, 21, 22, 21, 21, 21, 22, 21, 21, 21, 21, 22, 22, 21, 22,\n",
       "       21, 22, 22, 21, 21, 21, 21, 21, 21, 21, 22, 22, 21, 22, 21, 21, 22,\n",
       "       22, 22, 21, 21, 21, 22, 21, 22, 22, 22, 21, 22, 22, 21, 21, 21, 21,\n",
       "       21, 22, 22, 22, 21, 21, 21, 21, 22, 22, 22, 21, 21, 22, 22, 21, 22,\n",
       "       21, 22, 21, 21, 22, 21, 22, 21, 22, 21, 21, 21, 22, 21, 22, 21, 21,\n",
       "       22, 22, 22, 22, 21, 21, 22, 22, 22, 21, 22, 21, 21, 21, 21, 21, 22,\n",
       "       21, 22, 22, 22, 21, 22, 21, 22, 21, 22, 22, 21, 21, 22, 21, 22, 21,\n",
       "       22, 21, 22, 21, 21, 21, 21, 21, 21, 22, 21, 21, 21, 21, 22, 21, 21,\n",
       "       22, 21, 21, 21, 22, 22, 21, 22, 22, 22, 22, 22, 21, 22, 21, 22, 22,\n",
       "       22, 21, 21, 22, 22, 21, 21, 21, 22, 22, 22, 22, 22, 21, 22, 22, 21,\n",
       "       22, 21, 22, 21, 22, 21, 22, 22, 22, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "       21, 22, 21, 21, 21, 21, 21, 21, 21, 22, 21, 21, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 21, 22, 22, 22, 21, 22,\n",
       "       21, 21, 21, 21, 21, 22, 21, 21, 22, 21, 21, 22, 21, 21, 22, 21, 21,\n",
       "       22, 22, 22, 21, 21, 22, 22, 21, 21, 21, 22, 22, 21, 22, 22, 22, 21,\n",
       "       22, 21, 22, 21, 21, 21, 22, 22, 22, 21, 22, 22, 21, 21, 21, 21, 21,\n",
       "       22, 21, 21, 21, 21, 22, 22, 21, 22, 21, 22, 21, 21, 21, 21, 21, 22,\n",
       "       21, 21, 21, 21, 22, 22, 21, 21, 21, 21, 22, 21, 21, 21, 21, 22, 21,\n",
       "       22, 21, 22, 22, 22, 21, 22, 22, 22, 22, 22, 22, 21, 21, 21, 21, 22,\n",
       "       21, 22, 22, 22, 22, 22, 22, 21, 21, 21, 22, 21, 22, 21, 22, 22, 21,\n",
       "       21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 21, 22, 22, 22, 22, 22, 22,\n",
       "       21, 21, 22, 22, 21, 21, 22, 22, 21, 21, 22, 22, 22, 21, 21, 22, 22,\n",
       "       21, 21, 22, 21, 21, 22, 22, 22, 22, 21, 22, 22, 21, 21, 21, 21, 22,\n",
       "       22, 22, 21, 21, 21, 21, 22, 22, 21, 21, 21, 21, 21, 22, 21, 22, 21,\n",
       "       21, 22, 21, 21, 22, 21, 22, 22, 21, 22, 21, 21, 22, 21, 21, 21, 22,\n",
       "       21, 21, 21, 21, 21, 21, 21, 21, 22, 21, 21, 21, 21, 22, 22, 22, 21,\n",
       "       21, 21, 22, 22, 22, 22, 21, 21, 21, 21, 22, 22, 21, 22, 21, 22, 21,\n",
       "       22, 21, 22, 21, 21, 22, 21, 21, 21, 22, 21, 22, 21, 21],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction # The index value of Yes or No . If value is 21 then answer is Yes and if the value is 22, the answer is No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the same from test_answers so that we can compare the reult\n",
    "test_answers = test_answers.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          21       0.77      0.89      0.82       497\n",
      "          22       0.87      0.74      0.80       503\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.81      0.81      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_answers,final_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We got the accuracy of 81%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test it on few test cases\n",
    "# 1:\n",
    "statement = 'John moved to bedroom . Sandra is in the kitchen .'\n",
    "q1 = 'is John in the bedroom ?' # answer should be yes\n",
    "q2 = 'is Sandra in the kitchen ?' # answer should be yes\n",
    "\n",
    "ans1 = 'yes'\n",
    "ans2 = 'yes'\n",
    "\n",
    "# Let's change it to proper format\n",
    "statement = statement.split()\n",
    "q1 = q1.split()\n",
    "q2 = q2.split()\n",
    "\n",
    "data1= [(statement,q1,ans1)]\n",
    "data2 = [(statement,q2,ans2)]\n",
    "\n",
    "# Let's send it to function vectorize\n",
    "statement,question1,answer1 = vectorize(data1)\n",
    "statement,question2,answer2 = vectorize(data2)\n",
    "\n",
    "# Prediction on q1\n",
    "predict_q1 = model.predict([statement,question1])\n",
    "\n",
    "# prediction on q2\n",
    "predict_q2 = model.predict([statement,question2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the prediction on q1\n",
    "predict_q1.argmax()# 21 is the value for 'yes' and 22 is the value for 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the prediction on q2\n",
    "predict_q2.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2:\n",
    "statement = 'Daniel left the office . John dropped the football in the garden .'\n",
    "q = 'Is the football in the office ?'\n",
    "ans = 'no'\n",
    "\n",
    "# proper format\n",
    "statement = statement.split()\n",
    "q = q.split()\n",
    "\n",
    "data = [(statement,q,ans)]\n",
    "\n",
    "statement,q,ans = vectorize(data)\n",
    "\n",
    "# Prediction\n",
    "predict = model.predict([statement,q])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the output\n",
    "predict.argmax() # 22 if 'no',21 if 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
